+++
title="复杂度分析"
date=2020-03-12T23:02:48+08:00
categories=["数据结构与算法"]
tags=["复杂度分析"]
+++

### 事后统计法的局限性
1. 测试结果非常依赖测试环境
2. 测试结果受数据规模的影响很大

### 复杂度分析法
不用具体的测试数据来测试，就可以粗略的估计算法的执行效率的方法

### 大O复杂度表示法
算法的执行效率，粗略的讲就算算法代码执行的时间。这里有一段非常简单的代码，
我们来估算一下这段代码的执行时间：
```go
func cal(n int) int {
    sum := 0
    i := 1
    for ;i<=n;i++ {
        sum += i
    }
    
    return sum 
}
```
从CPU的角度来看，这段代码的每一行都执行类似的操作：**读数据-运算-写数据**。我们假设一行的执行时间为unit_time。那么第2，3行分别需要1个unit_time。4，5行都执行了n遍。这段代码总执行时间为2(n+1)*unit_time。
可以看出来，**所有代码的执行时间T(n)与每行代码的执行次数n成正比**

我们可以把这个规律总结成一个公式：
```
T(n) = O(f(n))

☛ T(n)：代码的执行时间
☛ n：数据规模的大小
☛ f(n)：每行代码执行的次数的总和
☛ O：表示T(n)与f(n)成正比
```
大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以也叫**渐进时间复杂度**，简称**时间复杂度**。

当n很大时，公式中的低价、常量、系数三部分并不左右增长的趋势，所以可以忽略，因此我们只需要记录一个最大量级就可以了。

### 时间复杂度分析
1. 只关注循环行数最多的一段代码
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
当无法确认哪个量级更大时，时间复杂度就是所有量级的和
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

### 几种常见时间复杂度实例分析
+ 多项式量级
  - 常量阶 O(1)
  - 对数阶 O(logn)
  - 线性阶 O(m+n) O(m*n)
  - 线性对数阶 O(nlogn)
  - k次方阶(k是常量) O(n^k)
+ 非多项式量级

   我们把时间复杂度为非多项式量级的算法问题叫作NP问题。
   当数据规模n越来越大时，非多项式量级算法执行时间会急剧增加，所以非多项式时间复杂度的算法其实是非常低效的算法
  - 指数阶 O(2^n)
  - 阶乘阶 O(n!)

### 空间复杂度分析
空间复杂度全称就是**渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系**

举个例子来说：
```go
func out(n int) {
  i := 0
  // 这里我们不考虑切片的扩容情景
	a := make([]int, n)
	for ; i < n; i++ {
		a[i] = i * i
	}

	for i = n - 1; i >= 0; i-- {
		fmt.Println(a[i])
	}
}
```
和时间复杂度一样，我们可以看到，第2行代码中，我们申请了一个空间存储变量i，但它是常量阶的，和数据规模n没有关系，所以我们可以忽略。第3行申请了一个大小为n的int类型切片。除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是O(n)。

我们常见的空间复杂度就是O(1)、O(n)、O(n^2)，像O(logn)、O(nlogn)这样的对数阶复杂度平时都用不到。

### 最好、最坏情况时间复杂度
```go
// n == len(array)
func find(n,x int, array []int) int {
  i := 0
  pos := -1
  for ;i<n;i++ {
    if array[i] == x {
      pos = i
    }
  }
  return pos
}
```
可以看出来，这段代码要实现的功能就是在无序数组中，查找变量x出现的位置。时间复杂度为O(n)。

我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为可能中途找到就提前结束循环了。我们优化一下这段代码再来看一下
```go
func find(n,x int, array []int) int {
  i := 0
  pos := -1
  for ;i<n;i++ {
    if array[i] == x {
      pos = i
      // 找到就跳出循环
      break
    }
  }
  return pos
}
```
我们考虑一下极端情况，如果第一个就找到了那么时间复杂度就是O(1)，如果不存在那么时间复杂度就是O(n)。所以不同情况下这段代码的时间复杂度是不一样的。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：**最好情况时间复杂度，最坏情况时间复杂度，平均情况时间复杂度**

### 平均情况时间复杂度
我们都知道，像最好最坏这种极端情况发生的概率其实并不大。为了更好的表示平均情况下的复杂度，我们就需要使用平均情况时间复杂度（简称平均时间复杂度）

我们还是用刚刚的例子，要查找变量在数组中的位置有n+1种情况：**在数组的0 ~ n-1位置中**和**不在数组中**。我们把每种情况下，需要遍历的元素个数累加起来，然后再除以n+1，就可以得到平均值，即：
```shell script
(1+2+3...+n+n)/(n+1)=n(n+3)/2(n+1)
```
我们省略常量，系数，低阶之后，得到的平均时间复杂度为O(n)。（注意：这里并没有引入概率）

只有在同一段代码在不同的情况西安，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。

### 均摊时间复杂度
```go
var count = 0

func insert(val int,array []int) {
	if count == len(array) {
		sum := 0
		for i:=0;i<len(array);i++ {
			sum += array[i]
		}
		array[0] = sum
		count = 1
	}

	array[count] = val
	count+=1
}
```
我们发现每次O(n)的操作之后都会跟着n-1次O(1)的插入操作。我们把耗时多的那次操作均摊到接下来的n-1次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是O(1)。这就是均摊分析的大致思路。
